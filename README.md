# AI-Coach Backend System

Ein modulares Backend-System f√ºr KI-gest√ºtzte Coaching-Anwendungen, entwickelt als Teil eines FIAE (Fachinformatiker Anwendungsentwicklung) Abschlussprojekts.

## ‚ö†Ô∏è Projekthinweis

**Dies ist ein Teilprojekt!** Die hier bereitgestellten Dateien zeigen die KI-Integration und das Test-Frontend. F√ºr einen vollst√§ndigen Betrieb werden zus√§tzliche Komponenten ben√∂tigt:

- Backend-Server (Express.js-Grundger√ºst)
- Datenbankschema und Migrations-Skripte
- Authentifizierungs-Middleware
- Weitere API-Endpoints
- Konfigurationsdateien

Die vorliegenden Dateien demonstrieren die **Kernfunktionalit√§t der KI-Integration** und k√∂nnen als Referenz f√ºr √§hnliche Projekte dienen.

## üìã Inhalt dieses Repositories

- `ai_router.js` - Express.js Router f√ºr KI-API-Integration (Gemini, OpenAI, DeepSeek)
- `index.html` - Test-Frontend f√ºr die KI-Chat-Funktionalit√§t mit Markdown-Rendering

## üéØ Projekt√ºbersicht

Das System erm√∂glicht die Integration verschiedener KI-Anbieter in eine Coaching-Plattform. Benutzer k√∂nnen mit unterschiedlichen KI-Modellen interagieren, wobei jeder "Coach" individuell konfiguriert werden kann.

### Hauptfunktionen

- **Multi-Provider-Support**: Integration von Google Gemini, OpenAI und DeepSeek
- **Kontextbasierte Chats**: Jeder Coach hat einen eigenen System-Prompt (Kontext)
- **Persistente Chat-Historie**: Speicherung aller Konversationen in MySQL-Datenbank
- **Dynamische Modellauswahl**: Abrufen und Ausw√§hlen verf√ºgbarer Modelle vom jeweiligen Anbieter
- **Redo-Funktionalit√§t**: L√∂schen und Wiederholen der letzten Interaktion
- **Markdown-Rendering**: Formatierte Darstellung von KI-Antworten (Tabellen, Listen, Code, etc.)

## üõ†Ô∏è Verwendete Technologien

### Backend (`ai_router.js`)
- **Node.js** & **Express.js** - Server-Framework
- **MySQL** (via `mysql2`) - Datenbankanbindung
- **Google Generative AI SDK** - Gemini API-Integration
- **OpenAI SDK** - OpenAI API-Integration
- **Custom API-Calls** - DeepSeek-Integration via Fetch

### Frontend (`index.html`)
- **Vanilla JavaScript** - Keine Frameworks
- **Fetch API** - HTTP-Requests an Backend
- **Marked.js** - Markdown-zu-HTML-Konvertierung
- **DOMPurify** - XSS-Schutz bei HTML-Rendering
- **CSS** - Responsive Chat-UI im Messenger-Stil

## üìä Datenbankstruktur (Erforderlich)

Das System ben√∂tigt folgende Tabellen in einer MySQL-Datenbank:

### Tabelle: `coaching_prompts`
```sql
CREATE TABLE coaching_prompts (
    coaching_id INT PRIMARY KEY AUTO_INCREMENT,
    context_prompt TEXT NOT NULL,
    api_key VARCHAR(255) NOT NULL,
    model VARCHAR(100) NOT NULL,
    api_provider ENUM('gemini', 'openai', 'deepseek') DEFAULT 'gemini',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### Tabelle: `chat_history`
```sql
CREATE TABLE chat_history (
    chat_id INT PRIMARY KEY AUTO_INCREMENT,
    user_id INT NOT NULL,
    coaching_id INT NOT NULL,
    role ENUM('user', 'model') NOT NULL,
    message_content TEXT NOT NULL,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (coaching_id) REFERENCES coaching_prompts(coaching_id)
);
```

### Tabelle: `users` (beispielhaft)
```sql
CREATE TABLE users (
    user_id INT PRIMARY KEY AUTO_INCREMENT,
    username VARCHAR(100) NOT NULL,
    email VARCHAR(255) NOT NULL UNIQUE,
    -- Weitere Felder nach Bedarf
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## üöÄ Installation & Konfiguration

### Voraussetzungen

- Node.js (v16 oder h√∂her)
- MySQL-Datenbank
- API-Keys f√ºr mindestens einen der unterst√ºtzten Anbieter:
  - [Google Gemini API](https://ai.google.dev/)
  - [OpenAI API](https://platform.openai.com/)
  - [DeepSeek API](https://www.deepseek.com/)

### Schritte

1. **Repository klonen**
```bash
git clone [repository-url]
cd ai-coach-backend
```

2. **Dependencies installieren**
```bash
npm install express mysql2 @google/generative-ai openai
```

3. **Datenbank konfigurieren**

Erstellen Sie eine Datei `ai-db.js` im Root-Verzeichnis:

```javascript
const mysql = require('mysql2/promise');

const pool = mysql.createPool({
    host: 'localhost',
    user: 'your_db_user',
    password: 'your_db_password',
    database: 'your_database_name',
    waitForConnections: true,
    connectionLimit: 10,
    queueLimit: 0
});

module.exports = pool;
```

4. **Datenbank-Tabellen erstellen**

F√ºhren Sie die SQL-Befehle aus dem Abschnitt "Datenbankstruktur" aus.

5. **Server-Grundger√ºst erstellen**

Erstellen Sie eine `server.js`:

```javascript
const express = require('express');
const cors = require('cors');
const aiRouter = require('./ai_router');

const app = express();
const PORT = 3000;

app.use(cors());
app.use(express.json());

// AI-Router einbinden
app.use('/api/ai', aiRouter);

app.listen(PORT, () => {
    console.log(`Server l√§uft auf http://localhost:${PORT}`);
});
```

6. **Server starten**
```bash
node server.js
```

7. **Test-Frontend √∂ffnen**

√ñffnen Sie `index.html` in einem Browser. Passen Sie die Backend-URL in der HTML-Datei an, falls erforderlich (Standard: `http://localhost:3000`).

## üì° API-Endpoints

### GET `/api/ai/models`
Ruft verf√ºgbare Modelle vom gew√§hlten Anbieter ab.

**Query-Parameter:**
- `apiKey` - API-Schl√ºssel des Anbieters
- `provider` - `gemini`, `openai` oder `deepseek`

**Response:**
```json
{
  "models": ["gemini-pro", "gemini-pro-vision", ...]
}
```

### POST `/api/ai/prompt`
Sendet eine Nachricht an die KI.

**Body:**
```json
{
  "prompt": "Benutzer-Nachricht",
  "userId": 1,
  "coachingId": 1,
  "apiProvider": "gemini",
  "baseUrl": "https://api.openai.com/v1" // Optional f√ºr OpenAI-kompatible APIs
}
```

**Response:**
```json
{
  "aiResponse": "KI-Antwort als Text"
}
```

### GET `/api/ai/history`
L√§dt die Chat-Historie.

**Query-Parameter:**
- `userId` - Benutzer-ID
- `coachingId` - (Optional) Coach-ID f√ºr gefilterte Historie

**Response:**
```json
{
  "history": [
    {
      "role": "user",
      "message": "Hallo"
    },
    {
      "role": "model",
      "message": "Hallo! Wie kann ich helfen?"
    }
  ]
}
```

### POST `/api/ai/history/delete_last`
L√∂scht die letzten beiden Nachrichten (User + KI).

**Body:**
```json
{
  "userId": 1,
  "coachingId": 1
}
```

### POST `/api/ai/coach/settings`
Aktualisiert Coach-Einstellungen.

**Body:**
```json
{
  "coachingId": 1,
  "contextPrompt": "Du bist ein hilfreicher Assistent...",
  "apiKey": "sk-...",
  "model": "gpt-4"
}
```

### GET `/api/ai/coach/settings/:coachingId`
L√§dt Coach-Einstellungen.

**Response:**
```json
{
  "context_prompt": "Du bist ein...",
  "api_key": "sk-...",
  "model": "gpt-4"
}
```

## üí° Verwendungsbeispiel

1. **Coach anlegen** (via Admin-Panel oder direkt in DB):
```sql
INSERT INTO coaching_prompts (context_prompt, api_key, model, api_provider)
VALUES ('Du bist ein freundlicher Karriere-Coach.', 'your-api-key', 'gemini-pro', 'gemini');
```

2. **Test-Frontend nutzen**:
   - Benutzer ausw√§hlen
   - Coach ausw√§hlen
   - Nachricht eingeben und senden
   - KI-Antwort wird formatiert angezeigt

3. **Chat-Historie** wird automatisch gespeichert und kann jederzeit abgerufen werden.

## üîí Sicherheitshinweise

‚ö†Ô∏è **Wichtig f√ºr Produktivumgebungen:**

- API-Keys niemals im Frontend oder in √∂ffentlichen Repositories speichern
- Umgebungsvariablen f√ºr sensible Daten verwenden (`.env`-Datei)
- Input-Validierung und Sanitization implementieren
- Rate-Limiting f√ºr API-Endpoints einrichten
- HTTPS in Produktion verwenden
- CORS-Einstellungen restriktiv konfigurieren
- SQL-Injection-Schutz durch Prepared Statements (bereits implementiert)

## üé® Frontend-Features

Das Test-Frontend (`index.html`) bietet:

- **Markdown-Rendering**: Tabellen, Listen, Code-Bl√∂cke, Fettdruck, etc.
- **Syntax-Highlighting**: F√ºr Code-Snippets
- **Kopier-Funktion**: F√ºr KI-Antworten
- **Redo-Button**: Letzte Antwort wiederholen
- **Admin-Bereich**: Coach-Verwaltung und Modellauswahl
- **Chat-Historie-Modal**: Gesamter Verlauf auf einen Blick
- **Responsive Design**: Messenger-√§hnliche UI

## üêõ Bekannte Einschr√§nkungen

- DeepSeek-API-Endpoint ist beispielhaft und muss ggf. angepasst werden
- Keine Authentifizierung im Router implementiert (muss extern erfolgen)
- Keine Fehlerbehandlung f√ºr Netzwerk-Timeouts
- Maximale Token-Limits der APIs werden nicht gepr√ºft

## üìö Erweiterungsm√∂glichkeiten

- **Streaming-Antworten**: Server-Sent Events f√ºr Echtzeit-Streaming
- **Datei-Uploads**: Bilder und Dokumente an KI senden
- **Multi-Modal**: Vision-Modelle f√ºr Bildanalyse
- **Webhooks**: Benachrichtigungen bei neuen Nachrichten
- **Analytics**: Tracking von API-Kosten und Nutzung
- **Caching**: Redis f√ºr h√§ufige Anfragen

## ü§ù Beitragen

Da dies ein Ausbildungsprojekt ist, sind Verbesserungsvorschl√§ge und Code-Reviews willkommen!

## üìù Lizenz

[F√ºgen Sie hier Ihre Lizenz ein]

## üë§ Autor

Entwickelt als Teil des FIAE-Abschlussprojekts

## üìû Support

Bei Fragen zu diesem Projekt erstellen Sie bitte ein Issue im Repository.

---

**Hinweis**: Dies ist ein Teilprojekt eines gr√∂√üeren Systems. Die hier gezeigten Komponenten demonstrieren die KI-Integration und sind nicht als standalone-L√∂sung gedacht.
